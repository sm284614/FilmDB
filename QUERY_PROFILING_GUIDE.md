# FilmDB Query Profiling Guide

This guide explains how to profile and analyze database query performance in FilmDB to make informed decisions about using LINQ vs Stored Procedures.

## üéØ Quick Start

### 1. Built-in Web Profiler (Easiest)

**Access:** Navigate to `https://localhost:5001/Diagnostics/QueryPerformance` (Development only)

**Features:**
- Run 7 different query performance tests
- See average, min, max, and median execution times
- Performance ratings (Excellent/Good/Fair/Slow)
- Tests all common query patterns in FilmDB

**How to Use:**
1. Start your application in Development mode
2. Navigate to `/Diagnostics/QueryPerformance`
3. Click "Run Query Performance Tests"
4. Review results to identify slow queries (>500ms)

**What Gets Tested:**
1. **Simple Film Lookup** - Basic single-entity query
2. **Genre Bitfield Filter** - Bitwise operations performance
3. **Year Range + Genre Filter** - Combined filtering
4. **Film Details with Cast/Crew Join** - Complex joins
5. **Person Filmography with Aggregation** - GroupBy performance
6. **Person Collaboration Query** - Most complex multi-join query
7. **Genre Film Count by Year** - GroupBy aggregation

### 2. Console SQL Logging (Always On in Development)

**What You'll See:**
```
[REQUEST] GET /Film/Details/1 - 45ms

info: Microsoft.EntityFrameworkCore.Database.Command[20101]
      Executed DbCommand (12ms) [Parameters=[@__id_0='1'], CommandType='Text', CommandTimeout='30']
      SELECT TOP(1) [f].[FilmId], [f].[Title], [f].[Year], [f].[Runtime], [f].[GenreBitField]
      FROM [Film] AS [f]
      WHERE [f].[FilmId] = @__id_0

[REQUEST] GET /Film/Details/1 - 45ms
```

**Features:**
- Shows actual SQL generated by EF Core
- Parameter values included (EnableSensitiveDataLogging)
- Execution time for each query
- Request-level timing

**Analyzing Output:**
- Look for queries taking >100ms
- Check for N+1 query patterns (same query repeated)
- Identify queries loading too much data
- Find queries that could benefit from indexes

### 3. SQL Server Profiler (Most Detailed)

**Requirements:**
- SQL Server Management Studio (SSMS) installed
- Access to `JSX2016\SQLEXPRESS`

**Setup Instructions:**

1. **Open SQL Server Profiler:**
   - Launch SSMS
   - Go to **Tools ‚Üí SQL Server Profiler**
   - Click **File ‚Üí New Trace**

2. **Connect to Your Database:**
   - Server: `JSX2016\SQLEXPRESS`
   - Authentication: Windows Authentication

3. **Configure Events (Events Selection Tab):**
   ```
   ‚úì RPC:Completed
   ‚úì SQL:BatchCompleted
   ‚úì SQL:BatchStarting (optional)
   ```

4. **Add Columns (Column Filters):**
   - Duration (ms)
   - CPU (ms)
   - Reads (logical I/O)
   - Writes (logical I/O)
   - DatabaseName
   - TextData (SQL query)

5. **Set Filters:**
   - **DatabaseName:** `Like` ‚Üí `FilmDB`
   - **Duration:** `Greater than or equal` ‚Üí `100` (only show queries >100ms)

6. **Start Tracing:**
   - Click **Run** to start the trace
   - Use your application normally
   - Watch queries appear in real-time

**What to Look For:**
- **High Duration** (>500ms) - Candidates for stored procedures
- **High Reads** (>1000) - Queries reading too much data
- **Repeated Queries** - N+1 problems or missing caching
- **Long CPU Time** - Queries doing heavy processing

### 4. Extended Events (Lightweight Alternative)

If Profiler is too heavy, use SQL Server Extended Events:

```sql
-- Create a session to capture slow queries
CREATE EVENT SESSION [FilmDB_SlowQueries] ON SERVER
ADD EVENT sqlserver.sql_statement_completed(
    ACTION(sqlserver.sql_text, sqlserver.database_name)
    WHERE (
        [duration] >= 100000  -- 100ms in microseconds
        AND [database_name] = N'FilmDB'
    )
)
ADD TARGET package0.ring_buffer
WITH (MAX_MEMORY=4096 KB);

-- Start the session
ALTER EVENT SESSION [FilmDB_SlowQueries] ON SERVER STATE = START;

-- View captured data
SELECT
    CAST(event_data AS XML) as event_data
FROM sys.fn_xe_file_target_read_file('FilmDB_SlowQueries*.xel', NULL, NULL, NULL);

-- Stop when done
ALTER EVENT SESSION [FilmDB_SlowQueries] ON SERVER STATE = STOP;
DROP EVENT SESSION [FilmDB_SlowQueries] ON SERVER;
```

## üìä Interpreting Results

### Performance Benchmarks

| Category | Time Range | Action |
|----------|-----------|--------|
| **Excellent** | < 50ms | Keep using LINQ |
| **Good** | 50-200ms | Monitor, keep LINQ |
| **Fair** | 200-500ms | Consider optimization (indexes, caching) |
| **Slow** | > 500ms | **Strong candidate for stored procedure** |

### Red Flags for Stored Procedures

Consider converting to stored procedures if you see:

1. **In-Memory Grouping**
   ```csharp
   .ToList()  // Loads all data
   .GroupBy(x => x.PersonId)  // Groups in .NET memory
   ```
   **Impact:** Loads entire result set into memory, then processes

2. **High Read Counts** (>10,000 logical reads)
   - Indicates too much data being scanned
   - Stored procedure could push aggregation to SQL Server

3. **Repeated Execution** (same query >100 times/minute)
   - Consider caching first
   - If not cacheable, SP might help with compiled plan

4. **Complex Multi-Table Joins** (5+ tables)
   - EF Core join translation can be inefficient
   - Hand-written SQL might be faster

## üîç Specific Query Analysis

### Example: Collaboration Query (PersonController.cs:210-243)

**Current LINQ:**
```csharp
var collaborations = (from fp1 in _db.Film_Person.AsNoTracking()
                      where fp1.PersonId == id
                      join fp2... join p... join j... join f...
                      select new {...})
                      .ToList()  // ‚ö†Ô∏è Loads everything to memory
                      .GroupBy(x => x.CollaboratorId)
```

**What Profiler Shows:**
- Duration: ~800ms
- Reads: 15,000+
- Two operations: 1) Large data fetch, 2) In-memory grouping

**Stored Procedure Would:**
```sql
-- Aggregate on SQL Server
SELECT
    fp2.PersonId,
    p.Name,
    COUNT(*) as CollaborationCount
FROM Film_Person fp1
JOIN Film_Person fp2 ON fp1.FilmId = fp2.FilmId
JOIN Person p ON fp2.PersonId = p.PersonId
WHERE fp1.PersonId = @PersonId
  AND fp2.PersonId != @PersonId
GROUP BY fp2.PersonId, p.Name
ORDER BY CollaborationCount DESC
```

**Expected Improvement:** 50-70% faster, much less memory

## üéõÔ∏è Optimization Strategies

### Before Converting to Stored Procedures:

1. **Add Indexes**
   ```csharp
   // Check ApplicationDbContext.cs for missing indexes
   modelBuilder.Entity<FilmPerson>()
       .HasIndex(fp => new { fp.FilmId, fp.PersonId });
   ```

2. **Use AsNoTracking()** (already done ‚úì)
   ```csharp
   _db.Film.AsNoTracking()  // 40% faster for read-only
   ```

3. **Implement Caching** (already done for common queries ‚úì)
   ```csharp
   _cache.GetOrCreate("genres", entry => {
       entry.AbsoluteExpirationRelativeToNow = TimeSpan.FromHours(24);
       return _db.Genre.AsNoTracking().ToList();
   });
   ```

4. **Use Projection** (Select only needed columns)
   ```csharp
   // Instead of:
   var films = _db.Film.ToList();  // Loads all columns

   // Use:
   var films = _db.Film
       .Select(f => new { f.FilmId, f.Title, f.Year })
       .ToList();
   ```

### When to Use Stored Procedures:

‚úÖ **Use SP if:**
- Query consistently >500ms after optimization
- Complex aggregations with GroupBy
- Fetching data just to group/aggregate in memory
- Batch operations (bulk insert/update/delete)

‚ùå **Keep LINQ if:**
- Query < 200ms
- Dynamic filtering (genres, years, search terms)
- Already cached effectively
- Simple CRUD operations

## üöÄ Next Steps

1. **Run the web profiler** at `/Diagnostics/QueryPerformance`
2. **Identify slow queries** (>500ms)
3. **Check console logs** for the SQL being generated
4. **Use SQL Server Profiler** for deep analysis of specific queries
5. **Try optimizations** (indexes, projections) before SPs
6. **Convert to SP only if** still slow after optimization

## üìù Making the Decision

Use this decision tree:

```
Is the query > 500ms?
‚îú‚îÄ No ‚Üí Keep LINQ ‚úì
‚îî‚îÄ Yes
    ‚îî‚îÄ Is it already cached?
        ‚îú‚îÄ Yes ‚Üí Keep LINQ ‚úì
        ‚îî‚îÄ No
            ‚îî‚îÄ Can it be cached?
                ‚îú‚îÄ Yes ‚Üí Cache it, keep LINQ ‚úì
                ‚îî‚îÄ No
                    ‚îî‚îÄ Does it aggregate data?
                        ‚îú‚îÄ Yes ‚Üí Use Stored Procedure ‚úì
                        ‚îî‚îÄ No ‚Üí Add indexes, try projection
                            ‚îî‚îÄ Still slow? ‚Üí Consider SP
```

## üîß Disabling Profiling in Production

The profiling is **automatically disabled in Production** (only runs in Development environment).

To disable console logging entirely:
```csharp
// In Program.cs, remove or comment out:
if (builder.Environment.IsDevelopment())
{
    // options.EnableSensitiveDataLogging();
    // options.LogTo(...);
}
```

---

**Remember:** Profile first, optimize second, stored procedure last!
